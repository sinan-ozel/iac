name: 02. Cluster

on:
  workflow_dispatch:
    inputs:
      provider:
        description: "Select the cloud provider"
        required: true
        type: choice
        options:
          - aws
          - exoscale

      config:
        description: "Select the .env file to use"
        required: true
        type: choice
        options:
          - hello-k8s-ca-central-1.env
          - kubyterlab-llm-ca-central-1.env
          - personal-cloud-ch-gva-2.env

      action:
        description: "Action to perform"
        required: true
        type: choice
        options:
          - provision
          - teardown
        default: provision

jobs:
  provision-teardown:
    env:
      PULUMI_CONFIG_PASSPHRASE: ${{ secrets.PULUMI_PASSPHRASE }}
      EXOSCALE_API_KEY: ${{ secrets.EXOSCALE_API_KEY }}
      EXOSCALE_API_SECRET: ${{ secrets.EXOSCALE_API_SECRET }}
      PULUMI_BACKEND_URL: file://${{ github.workspace }}/.pulumi-state
      PYTHONPATH: ${{ github.workspace }}
    name: Provision / Teardown Cluster
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Show platform uname
        run: uname -a

      - name: Install dependencies
        run: |
          pip install -r pulumi/${{ inputs.provider }}/requirements.txt

      - name: Install latest Pulumi CLI
        run: |
          pulumi version

      - name: Load the config
        run: |
          echo "Loading env file: ${{ inputs.config }}"
          set -a
          source "configs/${{ inputs.provider }}/${{ inputs.config }}"
          set +a
          grep -v '^#' "configs/${{ inputs.provider }}/${{ inputs.config }}" | grep -E '^[A-Za-z_][A-Za-z0-9_]*=' >> $GITHUB_ENV

      - name: Create AWS credentials secret
        if: github.event.inputs.provider == 'aws'
        run: |
          mkdir -p tmp
          printf "[default]\naws_access_key_id=%s\naws_secret_access_key=%s\nregion=%s\n" \
            "${{ secrets.AWS_ACCESS_KEY_ID }}" \
            "${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            "${{ env.REGION }}" > tmp/credentials

          AWS_SHARED_CREDENTIALS_FILE=tmp/credentials aws sts get-caller-identity
          ACCOUNT_ID=$(AWS_SHARED_CREDENTIALS_FILE=tmp/credentials aws sts get-caller-identity --query Account --output text)
          echo "AWS_ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV

      - name: Configure AWS credentials
        if: github.event.inputs.provider == 'aws'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/github-actions-iac
          aws-region: ${{ env.REGION }}

      - name: Configure Pulumi
        run: |
          echo "Configuring Pulumi..."
          pulumi version
          mkdir -p ${{ github.workspace }}/.pulumi-state
          pulumi login file://${{ github.workspace }}/.pulumi-state

      - name: Initialize Pulumi
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi stack init dev --non-interactive || echo "Stack dev already exists"

      - name: List stacks
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi stack ls

      - name: Select stack
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi stack select dev --non-interactive

      - name: Pulumi Preview
        if: ${{ inputs.action == 'provision' }}
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi preview

      - name: Pulumi Provision
        id: provision
        if: ${{ inputs.action == 'provision' }}
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi up --yes --non-interactive

      - name: Pulumi Teardown
        id: teardown
        if: ${{ inputs.action == 'teardown' }}
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi cancel --yes --non-interactive || echo "No ongoing update to cancel"
          pulumi destroy --yes --non-interactive

      - name: Commit Pulumi state
        if: always()
        run: |
          git config pull.rebase true
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"
          git add .pulumi-state
          git commit -m "Update Pulumi state after ${{ inputs.action }}" || echo "No changes to commit"
          git pull
          git push

      - name: Export Pulumi outputs
        if: steps.provision.conclusion == 'success'
        working-directory: pulumi/${{ inputs.provider }}
        run: |
          pulumi stack output --json > ${{ env.CLUSTER_NAME}}.json

      - name: Upload Pulumi outputs artifact
        if: steps.provision.conclusion == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: pulumi-${{ inputs.provider }}-${{ env.CLUSTER_NAME}}
          path: pulumi/${{ inputs.provider }}/${{ env.CLUSTER_NAME}}.json

      - name: Export Kubeconfig
        if: steps.provision.conclusion == 'success'
        run: |
          jq -r '.kubeconfig' pulumi/${{ inputs.provider }}/${{ env.CLUSTER_NAME}}.json > kubeconfig.yaml

      - name: Debug Kubernetes connectivity
        if: steps.provision.conclusion == 'success'
        run: |
          echo "Attempting to connect to Kubernetes cluster..."
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/stable.txt"
          KUBECTL_VERSION=$(cat stable.txt)
          curl -LO "https://dl.k8s.io/release/$KUBECTL_VERSION/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Use the generated kubeconfig file
          export KUBECONFIG=kubeconfig.yaml

          # Test kubectl commands
          echo "Getting cluster info:"
          kubectl --kubeconfig=kubeconfig.yaml cluster-info

          echo "Getting nodes:"
          kubectl --kubeconfig=kubeconfig.yaml get nodes -o wide

          echo "Getting all namespaces:"
          kubectl --kubeconfig=kubeconfig.yaml get namespaces

          echo "Getting all pods across all namespaces:"
          kubectl --kubeconfig=kubeconfig.yaml get pods --all-namespaces

      - name: Tag subnets
        if: steps.provision.conclusion == 'success'
        run: |
          python scripts/aws/cluster/tag_subnets.py pulumi/${{ inputs.provider }}/${{ env.CLUSTER_NAME}}.json
