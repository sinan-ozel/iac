name: 01. Bucket (Test)

on:
  workflow_dispatch:
    inputs:
      provider:
        description: "Select the cloud provider"
        required: true
        type: choice
        options:
          - aws

      config:
        description: "Select the .env file to use"
        required: true
        type: choice
        options:
          - notebooks.env

      action:
        description: "Action to perform"
        required: true
        type: choice
        options:
          - provision
          - teardown
        default: provision


jobs:
  provision-teardown:
    runs-on: ubuntu-latest
    # TODO: Test without the ca-central-1 env.
    env:
      BUCKET_NAME: delete-upbound-test-bucket

    permissions:
      contents: 'read'
    steps:
      # Common to all providers
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Kind
        uses: helm/kind-action@v1

      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.30.1'

      - name: Install the Up CLI
        run: |
          curl -sL "https://cli.upbound.io" | sh
          sudo mv up /usr/local/bin/
          up version
          up help

      - name: Install Upbound Universal Crossplane
        run: |
          up uxp install

      - name: Install Helm
        run: |
          echo "--- Let's try to access our kind cluster via kubectl"
          kubectl get nodes
          echo "‚è≥ Waiting for kube-apiserver to be ready..."
          for i in {1..30}; do
            ready=$(kubectl get --raw='/readyz' 2>/dev/null || true)
            if [[ "$ready" == "ok" ]]; then
              echo "‚úÖ API server ready"
              break
            fi
            sleep 5
          done
          if [[ "$ready" != "ok" ]]; then
            echo "‚ùå kube-apiserver did not become ready in time"
            exit 1
          fi
          echo "‚¨áÔ∏è Installing Helm"
          curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash

      - name: Wait for Crossplane core controllers to initialize
        run: |
          set -euo pipefail

          echo "‚è≥ Waiting for all Crossplane core controllers to become ready..."

          for i in {1..30}; do
            not_ready=$(kubectl -n upbound-system get pods \
              --selector=app.kubernetes.io/name=crossplane \
              --output=jsonpath='{range .items[?(@.status.containerStatuses[*].ready==false)]}{.metadata.name}{"\n"}{end}')

            if [[ -z "$not_ready" ]]; then
              echo "‚úÖ All Crossplane core controllers are ready."
              break
            fi

            echo "Waiting for the following pods to be ready:"
            echo "$not_ready"
            sleep 5
          done

          # Fail if still not ready after timeout
          if [[ -n "${not_ready:-}" ]]; then
            echo "‚ùå Timeout waiting for Crossplane controllers to be ready:"
            echo "$not_ready"
            kubectl -n upbound-system get pods
            exit 1
          fi

          echo "üì¶ Current Crossplane pod statuses:"
          kubectl -n upbound-system get pods

      - name: Set up environment variables from .env file
        id: dotenv
        run: |
          echo "Loading config: configs/${{ github.event.inputs.provider }}/${{ github.event.inputs.config }}"
          while IFS='=' read -r key value || [ -n "$key" ]; do
            if [[ ! "$key" =~ ^# && -n "$key" ]]; then
              echo "$key=$value" >> $GITHUB_ENV
            fi
          done < configs/${{ github.event.inputs.provider }}/${{ github.event.inputs.config }}

      # Provider
      - name: Install the Provider
        run: |
          echo "‚úÖ Waiting for Crossplane to be fully ready..."
          kubectl wait --for=condition=Available deployment/crossplane -n upbound-system --timeout=60s
          kubectl wait --for=condition=Available deployment/crossplane-rbac-manager -n upbound-system --timeout=60s
          kubectl apply -f crossplane/${{ github.event.inputs.provider }}/provider.yaml
          kubectl get providers

      # Just for AWS
      - name: Create AWS credentials secret
        if: github.event.inputs.provider == 'aws'
        run: |
          mkdir -p tmp
          printf "[default]\naws_access_key_id=%s\naws_secret_access_key=%s\nregion=%s\n" \
            "${{ secrets.AWS_ACCESS_KEY_ID }}" \
            "${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            "${{ env.REGION }}" > tmp/credentials

          kubectl create secret generic aws-credentials \
            -n upbound-system \
            --from-file=creds=tmp/credentials

          AWS_SHARED_CREDENTIALS_FILE=tmp/credentials aws sts get-caller-identity
          ACCOUNT_ID=$(AWS_SHARED_CREDENTIALS_FILE=tmp/credentials aws sts get-caller-identity --query Account --output text)
          echo "AWS_ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV

      - name: Wait for the provider to install
        run: |
          kubectl -n upbound-system get pods
          set -euo pipefail

          echo "üîç Scanning provider YAML files..."
          PROVIDER_NAMES=$(find crossplane/ -name provider.yaml -exec yq eval-all '.metadata.name' {} \; | grep -v '^\s*$' | grep -v '^---$' | sort -u)


          if [[ -z "$PROVIDER_NAMES" ]]; then
            echo "‚ùå No provider.yaml files found or missing metadata.name"
            exit 1
          fi

          echo "üîç Found provider names:"
          echo "$PROVIDER_NAMES"

          for PROVIDER in $PROVIDER_NAMES; do
            echo "‚è≥ Waiting for pod from provider: $PROVIDER"

            # Wait until at least one matching pod appears
            for i in {1..30}; do
              POD=$(kubectl get pods -n upbound-system -o name | grep "pod/$PROVIDER" || true)
              if [[ -n "$POD" ]]; then
                break
              fi
              echo "üîÑ Waiting for pod to be created for $PROVIDER..."
              sleep 5
            done

            if [[ -z "$POD" ]]; then
              echo "‚ùå No pod found for provider $PROVIDER"
              exit 1
            fi

            echo "‚úÖ Found pod: $POD"

            # Wait for the pod to be Ready (1/1 and Running)
            if ! kubectl wait --for=condition=Ready "$POD" -n upbound-system --timeout=150s; then
              echo "‚ùå Pod $POD did not become ready in time"
              kubectl describe "$POD" -n upbound-system || true
              exit 1
            fi

            echo "‚úÖ Pod $POD is ready"
          done

          echo "üéâ All provider pods are up and running!"
          kubectl -n upbound-system get pods

      # Provider Config
      - name: Install the ProviderConfig
        run: |
          kubectl apply -f crossplane/${{ inputs.provider }}/providerconfig.yaml
          kubectl get providerconfig

      # Provision
      - name: Deploy S3 bucket composition
        run: |
          envsubst < manifests/${{ github.event.inputs.provider }}/s3.yaml | kubectl apply -f -

      - name: Wait for Bucket to Become Ready
        run: |
          for i in {1..30}; do
            READY=$(kubectl get bucket ${{ env.BUCKET_NAME }} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "")
            if [[ "$READY" == "True" ]]; then
              echo "‚úÖ Bucket is ready"
              break
            fi
            echo "Waiting for bucket to be ready..."
            sleep 5
          done

          if [[ "$READY" != "True" ]]; then
            echo "‚ùå Bucket did not become ready after 150 seconds"
            kubectl get buckets
            kubectl describe bucket ${{ env.BUCKET_NAME }} || true
            kubectl -n upbound-system logs deploy/crossplane --tail=100
            kubectl get events --all-namespaces | grep ${{ env.BUCKET_NAME }} || true
            kubectl -n upbound-system logs deploy/provider-aws-controller-manager --tail=200
            exit 1
          fi

      # Teardown
      - name: Teardown S3 bucket composition
        if: github.event.inputs.action == 'teardown'
        run: |
          kubectl delete bucket ${{ env.BUCKET_NAME }} || echo "Already deleted or not found"
          if ! kubectl wait --for=delete bucket/${{ env.BUCKET_NAME }} --timeout=150s; then
            echo "‚ùå Timeout: Bucket '${{ env.BUCKET_NAME }}' was not deleted after 150 seconds"
            exit 1
          fi

          for i in {1..30}; do
            if ! kubectl get bucket ${{ env.BUCKET_NAME }} >/dev/null 2>&1; then
              echo "‚úÖ Bucket deleted from K8s"
              exit 0
            fi
            echo "‚è≥ Waiting for Bucket to be deleted..."
            sleep 5
          done
          echo "‚ùå Timeout: Bucket '${{ env.BUCKET_NAME }}' was not deleted after 150 seconds"
          exit 1